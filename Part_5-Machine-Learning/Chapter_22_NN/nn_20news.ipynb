{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kjmazidi/NLP/blob/master/Part_5-Machine-Learning/Chapter_22_NN/nn_20news.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Code accompanies *Natural Language Processing* by KJG Mazidi, all rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Multiclass Example\n",
    "\n",
    "This notebook runs the neural network algorithm on the 20 newsgroup data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', \n",
    "                                  categories=categories, shuffle=True, random_state=42)\n",
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                               batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "                               early_stopping=False, epsilon=1e-08,\n",
       "                               hidden_layer_sizes=(15, 7),\n",
       "                               learning_rate='constant',\n",
       "                               learning_rate_init=0.001, max_fun=15000,\n",
       "                               max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
       "                               nesterovs_momentum=True, power_t=0.5,\n",
       "                               random_state=1, shuffle=True, solver='lbfgs',\n",
       "                               tol=0.0001, validation_fraction=0.1,\n",
       "                               verbose=False, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "\n",
    "\n",
    "pipe1 = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('neuralnet', MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                   hidden_layer_sizes=(15, 7), random_state=1)),\n",
    "         ])\n",
    "\n",
    "pipe1.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.96      0.73      0.83       319\n",
      "         comp.graphics       0.93      0.89      0.91       389\n",
      "               sci.med       0.93      0.84      0.88       396\n",
      "soc.religion.christian       0.72      0.96      0.82       398\n",
      "\n",
      "              accuracy                           0.86      1502\n",
      "             macro avg       0.88      0.85      0.86      1502\n",
      "          weighted avg       0.88      0.86      0.86      1502\n",
      "\n",
      "Confusion matrix:\n",
      " [[234   2   9  74]\n",
      " [  0 345  13  31]\n",
      " [  5  16 332  43]\n",
      " [  6   9   2 381]]\n",
      "\n",
      "Overall accuracy:  0.8601864181091877\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test data\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "pred = pipe1.predict(twenty_test.data)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, pred,\n",
    "     target_names=twenty_test.target_names))\n",
    "\n",
    "print(\"Confusion matrix:\\n\", metrics.confusion_matrix(twenty_test.target, pred))\n",
    "\n",
    "import numpy as np\n",
    "print(\"\\nOverall accuracy: \", np.mean(pred==twenty_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural net classifier took longer to train and performed worse than logistic regression on this data. \n",
    "\n",
    "A network of (200, 67, 21, 7) got 88.5% accuracy.\n",
    "A network of (100, 67, 15, 7) got 87% accuracy. \n",
    "A network of (15, 7) got 86% accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
