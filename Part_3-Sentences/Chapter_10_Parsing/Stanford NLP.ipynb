{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford NLP\n",
    "\n",
    "*Note*: A newer, improved Python wrapper is Stanza. See the notebook in this folder. This notebook is here for those using the older stanfordnlp package. \n",
    "\n",
    "Stanford's [CoreNLP](https://stanfordnlp.github.io/CoreNLP/) system is a Java implementation of a full suite of NLP tools. The tools can be run from the command line, so implementation with a Python system could involve running a bash script to get and save the Java output which can then be processing using Python. There have been Python wrappers of CoreNLP but performance was an issue.\n",
    "\n",
    "Recently Stanford NLP released a [Python implementation](https://github.com/stanfordnlp/stanfordnlp) of some of the functionality. As of this writing, the NLP Pipeline tokenizes, pos tags, finds lemmas, and outputs a depenency parse. This notebook demonstrates this functionality. The link at the top of this paragraph provides installation instructions. The link also provides information about how to see sample notebooks in Google colab. One of the notebooks demonstrates how to set up a local server which will allow access to more functionality such as NER.\n",
    "\n",
    "Refer to the [documentation](https://pypi.org/project/stanfordnlp/) for installation and usage information.\n",
    "\n",
    "Running CoreNLP through Python will be slower with fewer options than running it in Java."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/mazidi/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/mazidi/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/Users/mazidi/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/mazidi/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/mazidi/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/Users/mazidi/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "\n",
    "nlp = stanfordnlp.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/TensorAdvancedIndexing.cpp:573: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "text = 'The history of natural language processing(NLP) generally started in the 1950s, \\\n",
    "although work can be found from earlier periods. In 1950, Alan Turing published an article\\\n",
    "titled \"Computing Machinery and Intelligence\" which proposed what is now called the\\\n",
    "Turing test as a criterion of intelligence.'\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sentence 1]\n",
      "The         \tthe         \tDT    \t2\tdet         \n",
      " \n",
      "history     \thistory     \tNN    \t11\tnsubj       \n",
      " \n",
      "of          \tof          \tIN    \t6\tcase        \n",
      " \n",
      "natural     \tnatural     \tJJ    \t5\tamod        \n",
      " \n",
      "language    \tlanguage    \tNN    \t6\tcompound    \n",
      " \n",
      "processing  \tprocessing  \tNN    \t2\tnmod        \n",
      " \n",
      "(           \t(           \t-LRB- \t8\tpunct       \n",
      " \n",
      "NLP         \tNLP         \tNN    \t6\tappos       \n",
      " \n",
      ")           \t)           \t-RRB- \t8\tpunct       \n",
      " \n",
      "generally   \tgenerally   \tRB    \t11\tadvmod      \n",
      " \n",
      "started     \tstart       \tVBD   \t0\troot        \n",
      " \n",
      "in          \tin          \tIN    \t14\tcase        \n",
      " \n",
      "the         \tthe         \tDT    \t14\tdet         \n",
      " \n",
      "1950s       \t1950        \tNNS   \t11\tobl         \n",
      " \n",
      ",           \t,           \t,     \t11\tpunct       \n",
      " \n",
      "although    \talthough    \tIN    \t20\tmark        \n",
      " \n",
      "work        \twork        \tNN    \t20\tnsubj:pass  \n",
      " \n",
      "can         \tcan         \tMD    \t20\taux         \n",
      " \n",
      "be          \tbe          \tVB    \t20\taux:pass    \n",
      " \n",
      "found       \tfind        \tVBN   \t11\tadvcl       \n",
      " \n",
      "from        \tfrom        \tIN    \t23\tcase        \n",
      " \n",
      "earlier     \tearlier     \tJJR   \t23\tamod        \n",
      " \n",
      "periods     \tperiod      \tNNS   \t20\tobl         \n",
      " \n",
      ".           \t.           \t.     \t11\tpunct       \n",
      " \n",
      "\n",
      "[Sentence 2]\n",
      "In          \tin          \tIN    \t2\tcase        \n",
      " \n",
      "1950        \t1950        \tCD    \t6\tobl         \n",
      " \n",
      ",           \t,           \t,     \t6\tpunct       \n",
      " \n",
      "Alan        \tAlan        \tNNP   \t6\tnsubj       \n",
      " \n",
      "Turing      \tturing      \tNNP   \t4\tflat        \n",
      " \n",
      "published   \tpublish     \tVBD   \t0\troot        \n",
      " \n",
      "an          \ta           \tDT    \t11\tdet         \n",
      " \n",
      "articletitled\tarticletitled\tVBN   \t11\tamod        \n",
      " \n",
      "\"           \t\"           \t``    \t11\tpunct       \n",
      " \n",
      "Computing   \tcomputing   \tNNP   \t11\tcompound    \n",
      " \n",
      "Machinery   \tMachinery   \tNNP   \t6\tobj         \n",
      " \n",
      "and         \tand         \tCC    \t13\tcc          \n",
      " \n",
      "Intelligence\tIntelligence\tNNP   \t11\tconj        \n",
      " \n",
      "\"           \t\"           \t''    \t11\tpunct       \n",
      " \n",
      "which       \twhich       \tWDT   \t16\tnsubj       \n",
      " \n",
      "proposed    \tpropose     \tVBD   \t11\tacl:relcl   \n",
      " \n",
      "what        \twhat        \tWP    \t20\tnsubj:pass  \n",
      " \n",
      "is          \tbe          \tVBZ   \t20\taux:pass    \n",
      " \n",
      "now         \tnow         \tRB    \t20\tadvmod      \n",
      " \n",
      "called      \tcall        \tVBN   \t16\tccomp       \n",
      " \n",
      "theTuring   \ttheture     \tVBG   \t20\txcomp       \n",
      " \n",
      "test        \ttest        \tNN    \t21\tobj         \n",
      " \n",
      "as          \tas          \tIN    \t25\tcase        \n",
      " \n",
      "a           \ta           \tDT    \t25\tdet         \n",
      " \n",
      "criterion   \tcriterion   \tNN    \t21\tobl         \n",
      " \n",
      "of          \tof          \tIN    \t27\tcase        \n",
      " \n",
      "intelligence\tintelligence\tNN    \t25\tnmod        \n",
      " \n",
      ".           \t.           \t.     \t6\tpunct       \n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print('\\n[Sentence {}]'.format(i+1))\n",
    "    for word in sentence.words:\n",
    "        print('{:12s}\\t{:12s}\\t{:6s}\\t{:d}\\t{:12s}'.format(\\\n",
    "            word.text, word.lemma, word.pos, word.governor, word.dependency_relation))\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also start a server to process sentences. Read more in [the documentation here](https://github.com/stanfordnlp/stanfordnlp/blob/master/demo/corenlp.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CORENLP_HOME\"] = r'/Users/mazidi/stanford-corenlp-4.1.0'\n",
    "\n",
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server with command: java -Xmx16G -cp /Users/mazidi/stanford-corenlp-4.1.0/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-a70f7fb6c42b441e.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse\n",
      "---\n",
      "dependency parse of first sentence\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 1\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 2\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 3\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 4\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 5\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 6\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 7\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 8\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 9\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 10\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 11\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 12\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 13\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 14\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 15\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 16\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 17\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 18\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 19\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 20\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 21\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 22\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 23\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 24\n",
      "}\n",
      "edge {\n",
      "  source: 2\n",
      "  target: 1\n",
      "  dep: \"det\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 2\n",
      "  target: 6\n",
      "  dep: \"nmod\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 5\n",
      "  target: 4\n",
      "  dep: \"amod\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 6\n",
      "  target: 3\n",
      "  dep: \"case\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 6\n",
      "  target: 5\n",
      "  dep: \"compound\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 6\n",
      "  target: 7\n",
      "  dep: \"punct\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 6\n",
      "  target: 8\n",
      "  dep: \"dep\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: Any\n",
      "}\n",
      "edge {\n",
      "  source: 11\n",
      "  target: 2\n",
      "  dep: \"nsubj\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 11\n",
      "  target: 20\n",
      "  dep: \"advcl\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 11\n",
      "  target: 24\n",
      "  dep: \"punct\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 11\n",
      "  target: 9\n",
      "  dep: \"punct\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 11\n",
      "  target: 10\n",
      "  dep: \"advmod\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 11\n",
      "  target: 14\n",
      "  dep: \"obl\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 11\n",
      "  target: 15\n",
      "  dep: \"punct\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 14\n",
      "  target: 12\n",
      "  dep: \"case\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 14\n",
      "  target: 13\n",
      "  dep: \"det\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 20\n",
      "  target: 16\n",
      "  dep: \"mark\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 20\n",
      "  target: 17\n",
      "  dep: \"nsubj:pass\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 20\n",
      "  target: 18\n",
      "  dep: \"aux\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 20\n",
      "  target: 19\n",
      "  dep: \"aux:pass\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 20\n",
      "  target: 23\n",
      "  dep: \"obl\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 23\n",
      "  target: 21\n",
      "  dep: \"case\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 23\n",
      "  target: 22\n",
      "  dep: \"amod\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "root: 11\n",
      "\n",
      "---\n",
      "constituency parse of first sentence\n",
      "child {\n",
      "  child {\n",
      "    child {\n",
      "      child {\n",
      "        child {\n",
      "          value: \"The\"\n",
      "        }\n",
      "        value: \"DT\"\n",
      "        score: -2.581110954284668\n",
      "      }\n",
      "      child {\n",
      "        child {\n",
      "          value: \"history\"\n",
      "        }\n",
      "        value: \"NN\"\n",
      "        score: -6.952702045440674\n",
      "      }\n",
      "      value: \"NP\"\n",
      "      score: -11.132145881652832\n",
      "    }\n",
      "    child {\n",
      "      child {\n",
      "        child {\n",
      "          value: \"of\"\n",
      "        }\n",
      "        value: \"IN\"\n",
      "        score: -0.6558045148849487\n",
      "      }\n",
      "      child {\n",
      "        child {\n",
      "          child {\n",
      "            child {\n",
      "              value: \"natural\"\n",
      "            }\n",
      "            value: \"JJ\"\n",
      "            score: -4.842470645904541\n",
      "          }\n",
      "          child {\n",
      "            child {\n",
      "              value: \"language\"\n",
      "            }\n",
      "            value: \"NN\"\n",
      "            score: -6.83102560043335\n",
      "          }\n",
      "          value: \"NML\"\n",
      "          score: -14.428268432617188\n",
      "        }\n",
      "        child {\n",
      "          child {\n",
      "            value: \"processing\"\n",
      "          }\n",
      "          value: \"NN\"\n",
      "          score: -8.318517684936523\n",
      "        }\n",
      "        child {\n",
      "          child {\n",
      "            child {\n",
      "              value: \"(\"\n",
      "            }\n",
      "            value: \"-LRB-\"\n",
      "            score: -0.4009050130844116\n",
      "          }\n",
      "          child {\n",
      "            child {\n",
      "              child {\n",
      "                value: \"NLP\"\n",
      "              }\n",
      "              value: \"NN\"\n",
      "              score: -15.184158325195312\n",
      "            }\n",
      "            value: \"NP\"\n",
      "            score: -17.78438949584961\n",
      "          }\n",
      "          child {\n",
      "            child {\n",
      "              value: \")\"\n",
      "            }\n",
      "            value: \"-RRB-\"\n",
      "            score: -0.40145066380500793\n",
      "          }\n",
      "          value: \"PRN\"\n",
      "          score: -19.217533111572266\n",
      "        }\n",
      "        value: \"NP\"\n",
      "        score: -49.51448440551758\n",
      "      }\n",
      "      value: \"PP\"\n",
      "      score: -52.2238883972168\n",
      "    }\n",
      "    value: \"NP\"\n",
      "    score: -63.81147766113281\n",
      "  }\n",
      "  child {\n",
      "    child {\n",
      "      child {\n",
      "        value: \"generally\"\n",
      "      }\n",
      "      value: \"RB\"\n",
      "      score: -5.748231887817383\n",
      "    }\n",
      "    value: \"ADVP\"\n",
      "    score: -5.839203834533691\n",
      "  }\n",
      "  child {\n",
      "    child {\n",
      "      child {\n",
      "        value: \"started\"\n",
      "      }\n",
      "      value: \"VBD\"\n",
      "      score: -5.215487957000732\n",
      "    }\n",
      "    child {\n",
      "      child {\n",
      "        child {\n",
      "          value: \"in\"\n",
      "        }\n",
      "        value: \"IN\"\n",
      "        score: -1.6812514066696167\n",
      "      }\n",
      "      child {\n",
      "        child {\n",
      "          child {\n",
      "            value: \"the\"\n",
      "          }\n",
      "          value: \"DT\"\n",
      "          score: -0.5893369317054749\n",
      "        }\n",
      "        child {\n",
      "          child {\n",
      "            value: \"1950s\"\n",
      "          }\n",
      "          value: \"NNS\"\n",
      "          score: -8.79506778717041\n",
      "        }\n",
      "        value: \"NP\"\n",
      "        score: -13.000850677490234\n",
      "      }\n",
      "      value: \"PP\"\n",
      "      score: -15.204730987548828\n",
      "    }\n",
      "    child {\n",
      "      child {\n",
      "        value: \",\"\n",
      "      }\n",
      "      value: \",\"\n",
      "      score: -0.009031965397298336\n",
      "    }\n",
      "    child {\n",
      "      child {\n",
      "        child {\n",
      "          value: \"although\"\n",
      "        }\n",
      "        value: \"IN\"\n",
      "        score: -4.722508907318115\n",
      "      }\n",
      "      child {\n",
      "        child {\n",
      "          child {\n",
      "            child {\n",
      "              value: \"work\"\n",
      "            }\n",
      "            value: \"NN\"\n",
      "            score: -5.894752502441406\n",
      "          }\n",
      "          value: \"NP\"\n",
      "          score: -9.486190795898438\n",
      "        }\n",
      "        child {\n",
      "          child {\n",
      "            child {\n",
      "              value: \"can\"\n",
      "            }\n",
      "            value: \"MD\"\n",
      "            score: -2.079181671142578\n",
      "          }\n",
      "          child {\n",
      "            child {\n",
      "              child {\n",
      "                value: \"be\"\n",
      "              }\n",
      "              value: \"VB\"\n",
      "              score: -0.009304866194725037\n",
      "            }\n",
      "            child {\n",
      "              child {\n",
      "                child {\n",
      "                  value: \"found\"\n",
      "                }\n",
      "                value: \"VBN\"\n",
      "                score: -4.83398962020874\n",
      "              }\n",
      "              child {\n",
      "                child {\n",
      "                  child {\n",
      "                    value: \"from\"\n",
      "                  }\n",
      "                  value: \"IN\"\n",
      "                  score: -2.7546632289886475\n",
      "                }\n",
      "                child {\n",
      "                  child {\n",
      "                    child {\n",
      "                      value: \"earlier\"\n",
      "                    }\n",
      "                    value: \"JJR\"\n",
      "                    score: -3.3301615715026855\n",
      "                  }\n",
      "                  child {\n",
      "                    child {\n",
      "                      value: \"periods\"\n",
      "                    }\n",
      "                    value: \"NNS\"\n",
      "                    score: -8.21888542175293\n",
      "                  }\n",
      "                  value: \"NP\"\n",
      "                  score: -18.473535537719727\n",
      "                }\n",
      "                value: \"PP\"\n",
      "                score: -21.75082778930664\n",
      "              }\n",
      "              value: \"VP\"\n",
      "              score: -28.044282913208008\n",
      "            }\n",
      "            value: \"VP\"\n",
      "            score: -30.924161911010742\n",
      "          }\n",
      "          value: \"VP\"\n",
      "          score: -35.25981903076172\n",
      "        }\n",
      "        value: \"S\"\n",
      "        score: -45.082542419433594\n",
      "      }\n",
      "      value: \"SBAR\"\n",
      "      score: -50.1971435546875\n",
      "    }\n",
      "    value: \"VP\"\n",
      "    score: -79.09274291992188\n",
      "  }\n",
      "  child {\n",
      "    child {\n",
      "      value: \".\"\n",
      "    }\n",
      "    value: \".\"\n",
      "    score: -0.0575326532125473\n",
      "  }\n",
      "  value: \"S\"\n",
      "  score: -154.88291931152344\n",
      "}\n",
      "value: \"ROOT\"\n",
      "score: -155.05445861816406\n",
      "\n",
      "---\n",
      "first token of first sentence\n",
      "word: \"The\"\n",
      "pos: \"DT\"\n",
      "value: \"The\"\n",
      "before: \"\"\n",
      "after: \" \"\n",
      "originalText: \"The\"\n",
      "ner: \"O\"\n",
      "lemma: \"the\"\n",
      "beginChar: 0\n",
      "endChar: 3\n",
      "beginIndex: 0\n",
      "endIndex: 1\n",
      "tokenBeginIndex: 0\n",
      "tokenEndIndex: 1\n",
      "hasXmlContext: false\n",
      "isNewline: false\n",
      "coarseNER: \"O\"\n",
      "fineGrainedNER: \"O\"\n",
      "\n",
      "---\n",
      "part of speech tag of token\n",
      "DT\n",
      "---\n",
      "named entity tag of token\n",
      "O\n"
     ]
    }
   ],
   "source": [
    "# set up the client\n",
    "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner','parse','depparse'], timeout=60000, memory='16G') as client:\n",
    "    # submit the request to the server\n",
    "    ann = client.annotate(text)\n",
    "    \n",
    "    # first sentence\n",
    "    sentence = ann.sentence[0]\n",
    "    \n",
    "    \n",
    "    # get the dependency parse of the first sentence\n",
    "    print('---')\n",
    "    print('dependency parse of first sentence')\n",
    "    dependency_parse = sentence.basicDependencies\n",
    "    print(dependency_parse)\n",
    " \n",
    "    # get the constituency parse of the first sentence\n",
    "    print('---')\n",
    "    print('constituency parse of first sentence')\n",
    "    constituency_parse = sentence.parseTree\n",
    "    print(constituency_parse)\n",
    "\n",
    "    # get the first token of the first sentence\n",
    "    print('---')\n",
    "    print('first token of first sentence')\n",
    "    token = sentence.token[0]\n",
    "    print(token)\n",
    "    \n",
    "    # get the part-of-speech tag\n",
    "    print('---')\n",
    "    print('part of speech tag of token')\n",
    "    token.pos\n",
    "    print(token.pos)\n",
    "\n",
    "    # get the named entity tag\n",
    "    print('---')\n",
    "    print('named entity tag of token')\n",
    "    print(token.ner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
