{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFG: Using rules to check grammar\n",
    "\n",
    "The previous notebook demonstrated that a CFG can be used to generate sentences. CFG can also be used to check if an input sentence is grammatical. There are several algorithms such as CYK that can do this check. In this notebook we go through a few rounds of applying CFG grammar manually until we arrive at S.\n",
    "\n",
    "Using the same rules as before: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {'S' : [['NP', 'VP']],\n",
    "         'NP': [['DT', 'NN'], ['DT', 'JJ', 'NN']],\n",
    "         'VP': [['VB'], ['VB', 'PP']],\n",
    "         'PP': [['P', 'DT', 'NN']],\n",
    "         'JJ' : ['happy', 'sad', 'silly'],\n",
    "         'DT': ['a', 'the'],\n",
    "         'NN': ['cat', 'dog', 'clown'],\n",
    "         'VB': ['plays', 'runs'],\n",
    "         'P' : ['with', 'near', 'beside']\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a reversed dictionary so that items on rhs can be clasified quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NP VP': 'S',\n",
       " 'DT NN': 'NP',\n",
       " 'DT JJ NN': 'NP',\n",
       " 'VB': 'VP',\n",
       " 'VB PP': 'VP',\n",
       " 'P DT NN': 'PP',\n",
       " 'happy': 'JJ',\n",
       " 'sad': 'JJ',\n",
       " 'silly': 'JJ',\n",
       " 'a': 'DT',\n",
       " 'the': 'DT',\n",
       " 'cat': 'NN',\n",
       " 'dog': 'NN',\n",
       " 'clown': 'NN',\n",
       " 'plays': 'VB',\n",
       " 'runs': 'VB',\n",
       " 'with': 'P',\n",
       " 'near': 'P',\n",
       " 'beside': 'P'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary item:class\n",
    "\n",
    "class_dict = {}\n",
    "for rule in rules.keys():\n",
    "    if isinstance(rules[rule][0], str): # terminals\n",
    "        for token in rules[rule]:\n",
    "            class_dict[token] = rule\n",
    "    else:  # non-terminals\n",
    "        for lst in rules[rule]:\n",
    "            pattern = ' '.join(lst)\n",
    "            class_dict[pattern] = rule\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['DT'], ['JJ'], ['NN'], ['VB']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round 1: for each input token, assign one or more POS\n",
    "# in this example, there will be only one but in another set,\n",
    "#   a word like 'senses' could be a noun or verb\n",
    "    \n",
    "sentence = 'the happy cat plays'\n",
    "tokens = sentence.split()\n",
    "patterns = [[class_dict[t]] for t in tokens]\n",
    "patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words and patterns: ['the happy', 'happy cat', 'cat plays'] [['DT JJ'], ['JJ NN'], ['NN VB']]\n"
     ]
    }
   ],
   "source": [
    "# round 2: for each pattern, find any lhs rule that could have generated it\n",
    "# now the tokens are taken 2 at a time\n",
    "# in this example we only have one pos so the code is straightforward\n",
    "indices = [[i, i+1] for i in range(0, len(tokens)-1)]\n",
    "word_strings = [tokens[i]+' '+tokens[j] for i,j in indices]\n",
    "search_patterns = [[patterns[i][0]+' '+patterns[j][0]] for i,j in indices]\n",
    "print('words and patterns:', word_strings, search_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], []]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search patterns for dictionary matches and replace when match is found, else X\n",
    "new_patterns = []\n",
    "for i, patt in enumerate(search_patterns):\n",
    "    new_patt = []  # assume no match\n",
    "    for p in patt:\n",
    "        if p in class_dict:\n",
    "            new_patt.append(class_dict[p])\n",
    "    new_patterns.append(new_patt)\n",
    "new_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words and patterns: ['the happy cat', 'happy cat plays'] [['DT JJ NN'], ['JJ NN VB']]\n"
     ]
    }
   ],
   "source": [
    "# round 3: none of the lenth-2 patterns match, try length 3\n",
    "# since none of the patterns in round 2 matched we are just looking back at pos, only one choice\n",
    "indices = [[i, i+2] for i in range(0, len(tokens)-2)]\n",
    "word_strings = [tokens[i]+' '+tokens[i+1]+' '+tokens[j] for i,j in indices]\n",
    "search_patterns = [[patterns[i][0]+' '+patterns[i+1][0]+' '+patterns[j][0]] for i,j in indices]\n",
    "print('words and patterns:', word_strings, search_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NP'], []]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for maches\n",
    "new_patterns = []\n",
    "for i, patt in enumerate(search_patterns):\n",
    "    new_patt = []  # assume no match\n",
    "    for p in patt:\n",
    "        if p in class_dict:\n",
    "            new_patt.append(class_dict[p])\n",
    "    new_patterns.append(new_patt)\n",
    "new_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NP'], [], ['VP']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round 4: 'the happy cat' can be replace by 'NP'\n",
    "# the remainder of the sentence is 'plays' = 'VB'\n",
    "search_patterns = patterns[3:]\n",
    "for i, patt in enumerate(search_patterns):\n",
    "    new_patt = []  # assume no match\n",
    "    for p in patt:\n",
    "        if p in class_dict:\n",
    "            new_patt.append(class_dict[p])\n",
    "    new_patterns.append(new_patt)\n",
    "new_patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from here we can extract the pattern 'NP VP' which matches S\n",
    "The sentence is established to be grammatical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
