{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Wikipedia Data with gensim\n",
    "\n",
    "This notebook demonstrates how to process a Wikipedia dump with gensim. Portions of code were modified from [this blog post](https://www.kdnuggets.com/2017/11/building-wikipedia-text-corpus-nlp.html)\n",
    "\n",
    "Link to gensim: https://radimrehurek.com/gensim/\n",
    "\n",
    "Download an xml dump from here: https://dumps.wikimedia.org/enwiki/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import WikiCorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will convert the Wikipedia xml dump to a text corpus. This code takes the zipped .bz2 filename as the wiki dump filename and the corpus filename as the text output file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corpus(xml_dump_filename, corpus_filename):\n",
    "    \n",
    "    print('Creating wiki object . . .')\n",
    "    # create the wiki object\n",
    "    wiki = WikiCorpus(xml_dump_filename)\n",
    "\n",
    "    # process the data\n",
    "    with open(corpus_filename, 'w') as corpus_file:\n",
    "        i = 0\n",
    "        for text in wiki.get_texts():\n",
    "            corpus_file.write(bytes(' '.join(text), 'utf-8').decode('utf-8') + '\\n')\n",
    "            i = i + 1\n",
    "            if (i % 100000 == 0):\n",
    "                print('Processed ' + str(i) + ' articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: This takes several hours to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_in = 'enwiki-latest-pages-articles.xml.bz2'\n",
    "make_corpus(file_in, 'corpus.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the file may be huge, we need a function to examine just a few files at a time. The function below will look at 10 lines, which corresponds to 10 files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_corpus(corpus_filename):\n",
    "    with open(corpus_filename, 'r') as corpus_input:\n",
    "        while (1):\n",
    "            print(corpus_input.readline()[:100])\n",
    "            get_input = input('Type X to quit')\n",
    "            if get_input == 'X':\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anarchism is political philosophy and movement that rejects all involuntary coercive forms of hierar\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type X to quit X\n"
     ]
    }
   ],
   "source": [
    "# output a few lines\n",
    "\n",
    "check_corpus('corpus.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
