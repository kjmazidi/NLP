{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ten Great Things about TextBlob\n",
    "\n",
    "TextBlob is a Python library for text processing. Under the hood, TextBlob uses NLTK libraries but provides its own API.\n",
    "\n",
    "\n",
    "Read [the docs](https://textblob.readthedocs.io/en/dev/)\n",
    "\n",
    "[API reference](https://textblob.readthedocs.io/en/dev/api_reference.html#textblob.blob.TextBlob)\n",
    "\n",
    "TextBlob is a nice alternative to NLTK, and is in fact built on top of it. TextBlob is a happy medium between the education-grade code of NLTK and the industrial-grade code of spaCy.\n",
    "\n",
    "In order to use TextBlob methods, import textblob, then convert text to a TextBlob object. Then, you are ready to roll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"TextBlob is a Python (2 and 3) library for processing \n",
    "textual data. It provides a simple API for diving into common \n",
    "natural language processing (NLP) tasks such as part-of-speech \n",
    "tagging, noun phrase extraction, sentiment analysis, classification,\n",
    "translation, and more.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert raw text to a TextBlob object\n",
    "blob = TextBlob(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. POS tagging\n",
    "\n",
    "POS tagging in TextBlob is fast, and syntax involves minimal typing. Under the hood, the basic tagger is NLTK's TreeBank tagger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TextBlob', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('Python', 'NNP'),\n",
       " ('2', 'CD'),\n",
       " ('and', 'CC'),\n",
       " ('3', 'CD'),\n",
       " ('library', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('processing', 'VBG')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all the tags are already there in the TextBlob object!!\n",
    "\n",
    "blob.tags[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tokenize\n",
    "\n",
    "A TextBlob object is already tokenized by sentence and by word. TextBlob uses NTLK tokenizers under the hood. Text is first tokenized into sentences then words when the textblob is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"TextBlob is a Python (2 and 3) library for processing \n",
       " textual data.\"),\n",
       " Sentence(\"It provides a simple API for diving into common \n",
       " natural language processing (NLP) tasks such as part-of-speech \n",
       " tagging, noun phrase extraction, sentiment analysis, classification,\n",
       " translation, and more.\")]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob is a Python (2 and 3) library for processing \n",
      "textual data.\n",
      "It provides a simple API for diving into common \n",
      "natural language processing (NLP) tasks such as part-of-speech \n",
      "tagging, noun phrase extraction, sentiment analysis, classification,\n",
      "translation, and more.\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob.sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['TextBlob', 'is', 'a', 'Python', '2', 'and', '3', 'library', 'for', 'processing', 'textual', 'data', 'It', 'provides', 'a', 'simple', 'API', 'for', 'diving', 'into', 'common', 'natural', 'language', 'processing', 'NLP', 'tasks', 'such', 'as', 'part-of-speech', 'tagging', 'noun', 'phrase', 'extraction', 'sentiment', 'analysis', 'classification', 'translation', 'and', 'more'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TextBlob', 'textual', 'tasks', 'tagging', 'translation']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_words = [w for w in blob.words if w.lower().startswith('t')]\n",
    "t_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Lemmatize\n",
    "\n",
    "TextBlob objects are means for text passages. Functionality in TextBlob can be extracted on the word level as well by creating Word objects. The following shows how to create a Word object. However, every word in a TextBlob object is already a Word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alumni lemmatized: alumnus\n",
      "had lemmatized: had\n",
      "had lemmatized verb: have\n"
     ]
    }
   ],
   "source": [
    "from textblob import Word\n",
    "\n",
    "w = Word('alumni')\n",
    "print(w, 'lemmatized:', w.lemmatize())\n",
    "\n",
    "w = Word('had')\n",
    "print(w, 'lemmatized:', w.lemmatize())\n",
    "print(w, 'lemmatized verb:', w.lemmatize(\"v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. WordNet integration\n",
    "\n",
    "You can use many WordNet features from TextBlob directly without important anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a room where books are kept',\n",
       " 'a collection of literary documents or records kept for reference or borrowing',\n",
       " 'a depository built to contain books and other materials for reading and study',\n",
       " '(computing) a collection of standard programs and subroutines that are stored and available for immediate use',\n",
       " 'a building that houses a collection of books and other materials']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words[7].define()\n",
    "#blob.words[7].definitions  # this also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('library.n.01'),\n",
       " Synset('library.n.02'),\n",
       " Synset('library.n.03'),\n",
       " Synset('library.n.04'),\n",
       " Synset('library.n.05')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words[7].synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('library.n.01') : a room where books are kept\n",
      "Synset('library.n.02') : a collection of literary documents or records kept for reference or borrowing\n",
      "Synset('library.n.03') : a depository built to contain books and other materials for reading and study\n",
      "Synset('library.n.04') : (computing) a collection of standard programs and subroutines that are stored and available for immediate use\n",
      "Synset('library.n.05') : a building that houses a collection of books and other materials\n"
     ]
    }
   ],
   "source": [
    "for syn in blob.words[7].synsets:\n",
    "    print(syn, ':', syn.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Noun phrase extraction\n",
    "\n",
    "A noun phrase is a phrase with a noun as a head word. A noun phrase could be a noun by itself but every noun is not necessarily a noun phrase. \n",
    " \n",
    "Noun phrase extraction is often a first step in identifying key phrases in a text, or identifying entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['textblob', 'python', 'processing textual data', 'api', 'common natural language processing', 'nlp', 'noun phrase extraction', 'sentiment analysis'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract noun phrases\n",
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Ngrams\n",
    "\n",
    "Ngrams are easily extracted from a TextBlob object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['TextBlob', 'is', 'a']),\n",
       " WordList(['is', 'a', 'Python']),\n",
       " WordList(['a', 'Python', '2']),\n",
       " WordList(['Python', '2', 'and']),\n",
       " WordList(['2', 'and', '3']),\n",
       " WordList(['and', '3', 'library']),\n",
       " WordList(['3', 'library', 'for']),\n",
       " WordList(['library', 'for', 'processing']),\n",
       " WordList(['for', 'processing', 'textual']),\n",
       " WordList(['processing', 'textual', 'data']),\n",
       " WordList(['textual', 'data', 'It']),\n",
       " WordList(['data', 'It', 'provides']),\n",
       " WordList(['It', 'provides', 'a']),\n",
       " WordList(['provides', 'a', 'simple']),\n",
       " WordList(['a', 'simple', 'API']),\n",
       " WordList(['simple', 'API', 'for']),\n",
       " WordList(['API', 'for', 'diving']),\n",
       " WordList(['for', 'diving', 'into']),\n",
       " WordList(['diving', 'into', 'common']),\n",
       " WordList(['into', 'common', 'natural']),\n",
       " WordList(['common', 'natural', 'language']),\n",
       " WordList(['natural', 'language', 'processing']),\n",
       " WordList(['language', 'processing', 'NLP']),\n",
       " WordList(['processing', 'NLP', 'tasks']),\n",
       " WordList(['NLP', 'tasks', 'such']),\n",
       " WordList(['tasks', 'such', 'as']),\n",
       " WordList(['such', 'as', 'part-of-speech']),\n",
       " WordList(['as', 'part-of-speech', 'tagging']),\n",
       " WordList(['part-of-speech', 'tagging', 'noun']),\n",
       " WordList(['tagging', 'noun', 'phrase']),\n",
       " WordList(['noun', 'phrase', 'extraction']),\n",
       " WordList(['phrase', 'extraction', 'sentiment']),\n",
       " WordList(['extraction', 'sentiment', 'analysis']),\n",
       " WordList(['sentiment', 'analysis', 'classification']),\n",
       " WordList(['analysis', 'classification', 'translation']),\n",
       " WordList(['classification', 'translation', 'and']),\n",
       " WordList(['translation', 'and', 'more'])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Sentiment analysis\n",
    "\n",
    "Polarity ranges from -1.0 to +1.0. Subjectivity ranges from 0.0 to 1.0 where lower numbers are more objective and higher numbers are more subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.06000000000000001, subjectivity=0.4514285714285714)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.15000000000000002, subjectivity=0.75)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob2 = TextBlob(\"I hate seafood. I love spicy food.\")\n",
    "\n",
    "blob2.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Spelling correction\n",
    "\n",
    "Text is often messy. TextBlob can help clean it up. This is simple spell correction, and will not identify the wrong word, as in 'stake' for 'steak'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"The stake was perfect but service was horrible.\")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messy_text = \"The stake was purfect but service was horible.\"\n",
    "blob2 = TextBlob(messy_text)\n",
    "\n",
    "blob2.correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Language detection\n",
    "\n",
    "Uses Google Translate API and requires internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob2 = TextBlob(\"Hola amor\")\n",
    "blob2.detect_language()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Open source\n",
    "\n",
    "One of the benefits of the open source approach is that you can dig into the code and learn more. For example, if you want to know how the spell checker works, the code gives a link to the algorithm by Peter Norvig."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob also has text classification functionality, but other frameworks such as sklearn are probably a better choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
