{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford NLP\n",
    "\n",
    "Stanford's [CoreNLP](https://stanfordnlp.github.io/CoreNLP/) system is a Java implementation of a full suite of NLP tools. The tools can be run from the command line, so implementation with a Python system could involve running a bash script to get and save the Java output which can then be processing using Python. There have been Python wrappers of CoreNLP but performance was an issue.\n",
    "\n",
    "Recently Stanford NLP released a [Python implementation](https://github.com/stanfordnlp/stanfordnlp) of some of the functionality. As of this writing, the NLP Pipeline tokenizes, pos tags, finds lemmas, and outputs a depenency parse. This notebook demonstrates this functionality. The link at the top of this paragraph provides installation instructions. The link also provides information about how to see sample notebooks in Google colab. One of the notebooks demonstrates how to set up a local server which will allow access to more functionality such as NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/mazidi/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/mazidi/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/mazidi/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/mazidi/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/mazidi/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/home/mazidi/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "\n",
    "nlp = stanfordnlp.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('The history of natural language processing(NLP) generally started in the 1950s, \\\n",
    "although work can be found from earlier periods. In 1950, Alan Turing published an article\\\n",
    "titled \"Computing Machinery and Intelligence\" which proposed what is now called the\\\n",
    "Turing test as a criterion of intelligence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sentence 1]\n",
      "The         \tthe         \tDT    \t2\tdet         \n",
      " \n",
      "history     \thistory     \tNN    \t11\tnsubj       \n",
      " \n",
      "of          \tof          \tIN    \t6\tcase        \n",
      " \n",
      "natural     \tnatural     \tJJ    \t5\tamod        \n",
      " \n",
      "language    \tlanguage    \tNN    \t6\tcompound    \n",
      " \n",
      "processing  \tprocessing  \tNN    \t2\tnmod        \n",
      " \n",
      "(           \t(           \t-LRB- \t8\tpunct       \n",
      " \n",
      "NLP         \tNLP         \tNN    \t6\tappos       \n",
      " \n",
      ")           \t)           \t-RRB- \t8\tpunct       \n",
      " \n",
      "generally   \tgenerally   \tRB    \t11\tadvmod      \n",
      " \n",
      "started     \tstart       \tVBD   \t0\troot        \n",
      " \n",
      "in          \tin          \tIN    \t14\tcase        \n",
      " \n",
      "the         \tthe         \tDT    \t14\tdet         \n",
      " \n",
      "1950s       \t1950        \tNNS   \t11\tobl         \n",
      " \n",
      ",           \t,           \t,     \t11\tpunct       \n",
      " \n",
      "although    \talthough    \tIN    \t20\tmark        \n",
      " \n",
      "work        \twork        \tNN    \t20\tnsubj:pass  \n",
      " \n",
      "can         \tcan         \tMD    \t20\taux         \n",
      " \n",
      "be          \tbe          \tVB    \t20\taux:pass    \n",
      " \n",
      "found       \tfind        \tVBN   \t11\tadvcl       \n",
      " \n",
      "from        \tfrom        \tIN    \t23\tcase        \n",
      " \n",
      "earlier     \tearlier     \tJJR   \t23\tamod        \n",
      " \n",
      "periods     \tperiod      \tNNS   \t20\tobl         \n",
      " \n",
      ".           \t.           \t.     \t11\tpunct       \n",
      " \n",
      "\n",
      "[Sentence 2]\n",
      "In          \tin          \tIN    \t2\tcase        \n",
      " \n",
      "1950        \t1950        \tCD    \t6\tobl         \n",
      " \n",
      ",           \t,           \t,     \t6\tpunct       \n",
      " \n",
      "Alan        \tAlan        \tNNP   \t6\tnsubj       \n",
      " \n",
      "Turing      \tturing      \tNNP   \t4\tflat        \n",
      " \n",
      "published   \tpublish     \tVBD   \t0\troot        \n",
      " \n",
      "an          \ta           \tDT    \t11\tdet         \n",
      " \n",
      "articletitled\tarticletitled\tVBN   \t11\tamod        \n",
      " \n",
      "\"           \t\"           \t``    \t11\tpunct       \n",
      " \n",
      "Computing   \tcomputing   \tNNP   \t11\tcompound    \n",
      " \n",
      "Machinery   \tMachinery   \tNNP   \t6\tobj         \n",
      " \n",
      "and         \tand         \tCC    \t13\tcc          \n",
      " \n",
      "Intelligence\tIntelligence\tNNP   \t11\tconj        \n",
      " \n",
      "\"           \t\"           \t''    \t11\tpunct       \n",
      " \n",
      "which       \twhich       \tWDT   \t16\tnsubj       \n",
      " \n",
      "proposed    \tpropose     \tVBD   \t11\tacl:relcl   \n",
      " \n",
      "what        \twhat        \tWP    \t20\tnsubj:pass  \n",
      " \n",
      "is          \tbe          \tVBZ   \t20\taux:pass    \n",
      " \n",
      "now         \tnow         \tRB    \t20\tadvmod      \n",
      " \n",
      "called      \tcall        \tVBN   \t16\tccomp       \n",
      " \n",
      "theTuring   \ttheture     \tVBG   \t20\txcomp       \n",
      " \n",
      "test        \ttest        \tNN    \t21\tobj         \n",
      " \n",
      "as          \tas          \tIN    \t25\tcase        \n",
      " \n",
      "a           \ta           \tDT    \t25\tdet         \n",
      " \n",
      "criterion   \tcriterion   \tNN    \t21\tobl         \n",
      " \n",
      "of          \tof          \tIN    \t27\tcase        \n",
      " \n",
      "intelligence\tintelligence\tNN    \t25\tnmod        \n",
      " \n",
      ".           \t.           \t.     \t6\tpunct       \n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print('\\n[Sentence {}]'.format(i+1))\n",
    "    for word in sentence.words:\n",
    "        print('{:12s}\\t{:12s}\\t{:6s}\\t{:d}\\t{:12s}'.format(\\\n",
    "            word.text, word.lemma, word.pos, word.governor, word.dependency_relation))\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
