{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network on the Movie Reviews Data\n",
    "\n",
    "This notebook code is modified from Francois Challot's book *Deep Learning with Python*, published by Manning.\n",
    "\n",
    "This notebook tries different RNN models on the data. A previous notebook tried a Dense sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "maxlen = 500\n",
    "batch_size = 32\n",
    "\n",
    "# load the data\n",
    "(train_data, train_labels), (test_data, test_labels) = datasets.imdb.load_data(num_words=max_features)\n",
    "\n",
    "# pad the data to maxlen\n",
    "train_data = preprocessing.sequence.pad_sequences(train_data, maxlen=maxlen)\n",
    "test_data = preprocessing.sequence.pad_sequences(test_data, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a Sequential model with Embedding and SimpleRNN layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 32))\n",
    "model.add(layers.SimpleRNN(32))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 322,113\n",
      "Trainable params: 322,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 13s 83ms/step - loss: 0.5433 - accuracy: 0.7165 - val_loss: 0.3812 - val_accuracy: 0.8490\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 13s 83ms/step - loss: 0.3358 - accuracy: 0.8624 - val_loss: 0.4827 - val_accuracy: 0.7710\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 13s 83ms/step - loss: 0.2824 - accuracy: 0.8909 - val_loss: 0.4446 - val_accuracy: 0.8240\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 13s 83ms/step - loss: 0.2224 - accuracy: 0.9153 - val_loss: 0.3253 - val_accuracy: 0.8626\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 13s 83ms/step - loss: 0.1853 - accuracy: 0.9317 - val_loss: 0.6228 - val_accuracy: 0.7652\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 13s 83ms/step - loss: 0.1519 - accuracy: 0.9460 - val_loss: 0.3589 - val_accuracy: 0.8550\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 13s 83ms/step - loss: 0.1168 - accuracy: 0.9610 - val_loss: 0.3920 - val_accuracy: 0.8460\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 13s 83ms/step - loss: 0.0829 - accuracy: 0.9722 - val_loss: 0.4171 - val_accuracy: 0.8478\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 13s 82ms/step - loss: 0.0596 - accuracy: 0.9812 - val_loss: 0.5377 - val_accuracy: 0.8474\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 13s 83ms/step - loss: 0.0432 - accuracy: 0.9859 - val_loss: 0.5138 - val_accuracy: 0.8350\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "history = model.fit(train_data,\n",
    "                    train_labels,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84     12500\n",
      "           1       0.85      0.81      0.83     12500\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.84      0.83      0.83     25000\n",
      "weighted avg       0.84      0.83      0.83     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred = model.predict(test_data)\n",
    "pred = [1.0 if p>= 0.5 else 0.0 for p in pred]\n",
    "print(classification_report(test_labels, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SimpleRNN got a lower than the accuracy in the Dense Sequential models in previous notebooks. The SimpleRNN does not perform well on longer sequences such as text. Next, we try the more powerful LSTM. The first block of code below changes only one layer, the SimpleRNN is changed to LSTM.\n",
    "\n",
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model with LSTM\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 32))\n",
    "model.add(layers.LSTM(32))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 328,353\n",
      "Trainable params: 328,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 26s 168ms/step - loss: 0.5108 - accuracy: 0.7630 - val_loss: 0.3426 - val_accuracy: 0.8608\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 23s 150ms/step - loss: 0.2921 - accuracy: 0.8868 - val_loss: 0.3177 - val_accuracy: 0.8824\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 23s 149ms/step - loss: 0.2337 - accuracy: 0.9118 - val_loss: 0.2931 - val_accuracy: 0.8774\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 24s 150ms/step - loss: 0.1982 - accuracy: 0.9266 - val_loss: 0.3058 - val_accuracy: 0.8732\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 23s 149ms/step - loss: 0.1753 - accuracy: 0.9357 - val_loss: 0.4344 - val_accuracy: 0.8426\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 23s 149ms/step - loss: 0.1554 - accuracy: 0.9447 - val_loss: 0.3487 - val_accuracy: 0.8842\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 23s 149ms/step - loss: 0.1422 - accuracy: 0.9492 - val_loss: 0.3014 - val_accuracy: 0.8858\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 23s 149ms/step - loss: 0.1318 - accuracy: 0.9532 - val_loss: 0.3180 - val_accuracy: 0.8772\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 23s 149ms/step - loss: 0.1186 - accuracy: 0.9579 - val_loss: 0.3289 - val_accuracy: 0.8744\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 23s 149ms/step - loss: 0.1105 - accuracy: 0.9618 - val_loss: 0.5577 - val_accuracy: 0.8674\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "history = model.fit(train_data,\n",
    "                    train_labels,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.79      0.84     12500\n",
      "           1       0.81      0.91      0.86     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_data)\n",
    "pred = [1.0 if p>= 0.5 else 0.0 for p in pred]\n",
    "print(classification_report(test_labels, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSTM performed better than the Simple RNN but still not as good as the Dense Sequential model. For sentiment analysis, the presence or absence of words captured by the Dense Sequential model is more powerful than the LSTM model. However, there are many other NLP machine learning applications where LSTM outperforms a Dense Sequential model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try GRU\n",
    "\n",
    "Try a Gated recurrent unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 32))\n",
    "model.add(layers.GRU(32))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 27s 169ms/step - loss: 0.5229 - accuracy: 0.7310 - val_loss: 0.3418 - val_accuracy: 0.8590\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 23s 145ms/step - loss: 0.3112 - accuracy: 0.8706 - val_loss: 0.3202 - val_accuracy: 0.8734\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 24s 150ms/step - loss: 0.2484 - accuracy: 0.9020 - val_loss: 0.3467 - val_accuracy: 0.8774\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 24s 154ms/step - loss: 0.2198 - accuracy: 0.9177 - val_loss: 0.3330 - val_accuracy: 0.8568\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 23s 148ms/step - loss: 0.1960 - accuracy: 0.9253 - val_loss: 0.3230 - val_accuracy: 0.8648\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 23s 146ms/step - loss: 0.1754 - accuracy: 0.9364 - val_loss: 0.4423 - val_accuracy: 0.8092\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 23s 145ms/step - loss: 0.1583 - accuracy: 0.9423 - val_loss: 0.4918 - val_accuracy: 0.8494\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 23s 146ms/step - loss: 0.1493 - accuracy: 0.9462 - val_loss: 0.3474 - val_accuracy: 0.8618\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 23s 146ms/step - loss: 0.1304 - accuracy: 0.9539 - val_loss: 0.3780 - val_accuracy: 0.8680\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 23s 146ms/step - loss: 0.1267 - accuracy: 0.9554 - val_loss: 0.4906 - val_accuracy: 0.8672\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "history = model.fit(train_data,\n",
    "                    train_labels,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85     12500\n",
      "           1       0.91      0.76      0.83     12500\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.85      0.84      0.84     25000\n",
      "weighted avg       0.85      0.84      0.84     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_data)\n",
    "pred = [1.0 if p>= 0.5 else 0.0 for p in pred]\n",
    "print(classification_report(test_labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
