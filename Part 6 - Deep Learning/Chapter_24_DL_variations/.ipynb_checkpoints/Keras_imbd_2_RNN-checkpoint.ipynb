{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network on the Movie Reviews Data\n",
    "\n",
    "This notebook code is modified from Francois Challot's book *Deep Learning with Python*, published by Manning.\n",
    "\n",
    "This notebook tries different RNN models on the data. A previous notebook tried a Dense sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "maxlen = 500\n",
    "batch_size = 32\n",
    "\n",
    "# load the data\n",
    "(train_data, train_labels), (test_data, test_labels) = datasets.imdb.load_data(num_words=max_features)\n",
    "\n",
    "# pad the data to maxlen\n",
    "train_data = preprocessing.sequence.pad_sequences(train_data, maxlen=maxlen)\n",
    "test_data = preprocessing.sequence.pad_sequences(test_data, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a Sequential model with Embedding and SimpleRNN layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 32))\n",
    "model.add(layers.SimpleRNN(32))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 13s 82ms/step - loss: 0.6265 - accuracy: 0.6362 - val_loss: 0.4592 - val_accuracy: 0.7962\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 13s 81ms/step - loss: 0.3852 - accuracy: 0.8410 - val_loss: 0.3650 - val_accuracy: 0.8460\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 13s 82ms/step - loss: 0.2894 - accuracy: 0.8873 - val_loss: 0.4327 - val_accuracy: 0.7966\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 13s 82ms/step - loss: 0.2239 - accuracy: 0.9158 - val_loss: 0.3849 - val_accuracy: 0.8374\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 13s 82ms/step - loss: 0.1489 - accuracy: 0.9480 - val_loss: 0.4262 - val_accuracy: 0.8276\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 13s 82ms/step - loss: 0.1011 - accuracy: 0.9668 - val_loss: 0.3817 - val_accuracy: 0.8720\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 13s 82ms/step - loss: 0.0648 - accuracy: 0.9789 - val_loss: 0.5155 - val_accuracy: 0.8142\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 13s 82ms/step - loss: 0.0404 - accuracy: 0.9875 - val_loss: 0.5162 - val_accuracy: 0.8414\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 13s 81ms/step - loss: 0.0275 - accuracy: 0.9919 - val_loss: 0.7008 - val_accuracy: 0.7530\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 13s 82ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.8414 - val_accuracy: 0.7414\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "history = model.fit(train_data,\n",
    "                    train_labels,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74     12500\n",
      "           1       0.74      0.74      0.74     12500\n",
      "\n",
      "    accuracy                           0.74     25000\n",
      "   macro avg       0.74      0.74      0.74     25000\n",
      "weighted avg       0.74      0.74      0.74     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred = model.predict(test_data)\n",
    "pred = [1.0 if p>= 0.5 else 0.0 for p in pred]\n",
    "print(classification_report(test_labels, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SimpleRNN got 74% accuracy, which was lower than the accuracy in the Dense Sequential models in previous notebooks. The SimpleRNN does not perform well on longer sequences such as text. Next, we try the more powerful LSTM. The first block of code below changes only one layer, the SimpleRNN is changed to LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model with LSTM\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 32))\n",
    "model.add(layers.LSTM(32))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.5321 - accuracy: 0.7503 - val_loss: 0.3782 - val_accuracy: 0.8556\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 23s 148ms/step - loss: 0.3042 - accuracy: 0.8826 - val_loss: 0.5008 - val_accuracy: 0.8020\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 23s 148ms/step - loss: 0.2399 - accuracy: 0.9104 - val_loss: 0.3220 - val_accuracy: 0.8598\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 23s 146ms/step - loss: 0.2024 - accuracy: 0.9270 - val_loss: 0.3148 - val_accuracy: 0.8880\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 23s 147ms/step - loss: 0.1744 - accuracy: 0.9373 - val_loss: 0.3246 - val_accuracy: 0.8884\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 23s 148ms/step - loss: 0.1552 - accuracy: 0.9441 - val_loss: 0.4484 - val_accuracy: 0.8376\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 23s 147ms/step - loss: 0.1422 - accuracy: 0.9498 - val_loss: 0.3115 - val_accuracy: 0.8678\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 23s 150ms/step - loss: 0.1283 - accuracy: 0.9552 - val_loss: 0.3592 - val_accuracy: 0.8682\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 23s 147ms/step - loss: 0.1174 - accuracy: 0.9587 - val_loss: 0.3598 - val_accuracy: 0.8866\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 23s 148ms/step - loss: 0.1111 - accuracy: 0.9611 - val_loss: 0.5767 - val_accuracy: 0.8110\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "history = model.fit(train_data,\n",
    "                    train_labels,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82     12500\n",
      "           1       0.95      0.60      0.73     12500\n",
      "\n",
      "    accuracy                           0.78     25000\n",
      "   macro avg       0.83      0.78      0.77     25000\n",
      "weighted avg       0.83      0.78      0.77     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_data)\n",
    "pred = [1.0 if p>= 0.5 else 0.0 for p in pred]\n",
    "print(classification_report(test_labels, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSTM performed better than the Simple RNN but still not as good as the Dense Sequential model. For sentiment analysis, the presence or absence of words captured by the Dense Sequential model is more powerful than the LSTM model. However, there are many other NLP machine learning applications where LSTM outperforms a Dense Sequential model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
