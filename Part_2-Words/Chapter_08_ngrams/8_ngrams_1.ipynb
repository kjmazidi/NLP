{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kjmazidi/NLP/blob/master/Part_2-Words/Chapter_08_ngrams/8_ngrams_1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating N-gram Language Models\n",
    "\n",
    "Generate ngrams from text using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Code accompanies *Natural Language Processing* by KJG Mazidi, all rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we look at two ways to create ngrams from text:\n",
    "* using Python\n",
    "* using NLTK ngrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code block is needed if running on colab\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"jack be nimble. jack be quick. jack jump over \\\n",
    "the candlestick.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigrams are just the tokens in the text, so we can use NLTK's word_tokenize() function to get unigrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jack',\n",
       " 'be',\n",
       " 'nimble',\n",
       " '.',\n",
       " 'jack',\n",
       " 'be',\n",
       " 'quick',\n",
       " '.',\n",
       " 'jack',\n",
       " 'jump',\n",
       " 'over',\n",
       " 'the',\n",
       " 'candlestick',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "unigrams = word_tokenize(raw_text)\n",
    "unigrams "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigrams are just pairs of unigrams as we sequentially scan the text. The code below uses a list comprehension to create tuples of bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jack', 'be'),\n",
       " ('be', 'nimble'),\n",
       " ('nimble', '.'),\n",
       " ('.', 'jack'),\n",
       " ('jack', 'be'),\n",
       " ('be', 'quick'),\n",
       " ('quick', '.'),\n",
       " ('.', 'jack'),\n",
       " ('jack', 'jump'),\n",
       " ('jump', 'over'),\n",
       " ('over', 'the'),\n",
       " ('the', 'candlestick'),\n",
       " ('candlestick', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = [(unigrams[k], unigrams[k+1]) for k in range(len(unigrams)-1)]\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK ngrams() function produces the same result. Note that the second argument of ngrams() is the \"n\" of ngrams. If we wanted trigrams we would use 3:\n",
    "\n",
    "```\n",
    "ngrams(tokens, 3)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jack', 'be'),\n",
       " ('be', 'nimble'),\n",
       " ('nimble', '.'),\n",
       " ('.', 'jack'),\n",
       " ('jack', 'be'),\n",
       " ('be', 'quick'),\n",
       " ('quick', '.'),\n",
       " ('.', 'jack'),\n",
       " ('jack', 'jump'),\n",
       " ('jump', 'over'),\n",
       " ('over', 'the'),\n",
       " ('the', 'candlestick'),\n",
       " ('candlestick', '.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "tokens = word_tokenize(raw_text)\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, make dictionaries of counts for the unigrams and bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quick': 1,\n",
       " 'be': 2,\n",
       " 'jack': 3,\n",
       " 'candlestick': 1,\n",
       " '.': 3,\n",
       " 'jump': 1,\n",
       " 'nimble': 1,\n",
       " 'the': 1,\n",
       " 'over': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_dict = {t:unigrams.count(t) for t in set(unigrams)}\n",
    "unigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('over', 'the'): 1,\n",
       " ('jack', 'be'): 2,\n",
       " ('be', 'quick'): 1,\n",
       " ('jack', 'jump'): 1,\n",
       " ('candlestick', '.'): 1,\n",
       " ('jump', 'over'): 1,\n",
       " ('quick', '.'): 1,\n",
       " ('.', 'jack'): 2,\n",
       " ('be', 'nimble'): 1,\n",
       " ('nimble', '.'): 1,\n",
       " ('the', 'candlestick'): 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_dict = {b:bigrams.count(b) for b in set(bigrams)}\n",
    "bigram_dict\n",
    "# key is tuple, value is the count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that '. Jack' has count 2 when really 'Jack' starts 3 sentences. A way around this is to have a start symbol at the beginning of every sentence 'start-Jack'. However, in a really large corpus it won't make a huge difference in the counts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a probabilistic model\n",
    "\n",
    "Now that we have \"trained\" a model on our tiny corpus, we can compute probabilities on new data, which we will call test data. \n",
    "\n",
    "Calculate the P(Jack be nimble) = P(Jack be) * P(be nimble) using smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_prob(text, unigram_dict, bigram_dict, N, V):\n",
    "    # N is the number of tokens in the training data\n",
    "    # V is the vocabulary size in the training data (unique tokens)\n",
    "\n",
    "    unigrams_test = word_tokenize(text)\n",
    "    bigrams_test = list(ngrams(unigrams_test, 2))\n",
    "    \n",
    "    p_gt = 1       # calculate p using a variation of Good-Turing smoothing\n",
    "    p_laplace = 1  # calculate p using Laplace smoothing\n",
    "    p_log = 0      # add log(p) to prevent underflow\n",
    "\n",
    "    for bigram in bigrams_test:\n",
    "        n = bigram_dict[bigram] if bigram in bigram_dict else 0\n",
    "        n_gt = bigram_dict[bigram] if bigram in bigram_dict else 1/N\n",
    "        d = unigram_dict[bigram[0]] if bigram[0] in unigram_dict else 0\n",
    "        if d == 0:\n",
    "            p_gt = p_gt * (1 / N)\n",
    "        else:\n",
    "            p_gt = p_gt * (n_gt / d)\n",
    "        p_laplace = p_laplace * ((n + 1) / (d + V))\n",
    "        p_log = p_log + math.log((n + 1) / (d + V))\n",
    "\n",
    "    print(\"\\nprobability with simplified Good-Turing is %.5f\" % (p_gt))\n",
    "    print(\"probability with laplace smoothing is %.5f\" % p_laplace)\n",
    "    print(\"log prob is %.5f == %.5f\" % (p_log, math.exp(p_log)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "probability with simplified Good-Turing is 0.33333\n",
      "probability with laplace smoothing is 0.00909\n",
      "log prob is -4.70048 == 0.00909\n"
     ]
    }
   ],
   "source": [
    "N = len(unigrams)\n",
    "V = len(unigram_dict)\n",
    "\n",
    "test_text = 'jack be nimble.'\n",
    "\n",
    "compute_prob(test_text, unigram_dict, bigram_dict, N, V) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "probability with simplified Good-Turing is 0.00170\n",
      "probability with laplace smoothing is 0.00253\n",
      "log prob is -5.98141 == 0.00253\n"
     ]
    }
   ],
   "source": [
    "test_text = 'jack be smart.'\n",
    "\n",
    "compute_prob(test_text, unigram_dict, bigram_dict, N, V)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation from an ngram model\n",
    "\n",
    "Could be use these probabilities to generate text?\n",
    "\n",
    "First, create probability dictionaries from the corpus. Then we take a very naive approach to language generation. Given a start word, find the most likely next word. Continue, until you get a sentence end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram probs: {'quick': 0.07142857142857142, 'be': 0.14285714285714285, 'jack': 0.21428571428571427, 'candlestick': 0.07142857142857142, '.': 0.21428571428571427, 'jump': 0.07142857142857142, 'nimble': 0.07142857142857142, 'the': 0.07142857142857142, 'over': 0.07142857142857142}\n",
      "\n",
      "bigram probs: {('over', 'the'): 1.0, ('jack', 'be'): 0.6666666666666666, ('be', 'quick'): 0.5, ('jack', 'jump'): 0.3333333333333333, ('candlestick', '.'): 1.0, ('jump', 'over'): 1.0, ('quick', '.'): 1.0, ('.', 'jack'): 0.6666666666666666, ('be', 'nimble'): 0.5, ('nimble', '.'): 1.0, ('the', 'candlestick'): 1.0}\n"
     ]
    }
   ],
   "source": [
    "u_probs = {t:unigrams.count(t)/len(unigrams) for t in set(unigrams)}\n",
    "b_probs = {b:bigrams.count(b)/unigrams.count(b[0]) for b in set(bigrams)}\n",
    "\n",
    "print('unigram probs:', u_probs)\n",
    "print('\\nbigram probs:', b_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_gen(start_word, u_probs, b_probs):\n",
    "    phrase = [start_word]\n",
    "    while phrase[-1] != '.':\n",
    "        candidate_next = {k:b_probs[k] for k in b_probs if k[0] == phrase[-1]}\n",
    "        candidate_next = sorted(candidate_next.items(), key=lambda x:x[1], reverse=True)\n",
    "        if not candidate_next:\n",
    "            break\n",
    "        phrase += [candidate_next[0][0][1]]  # [0][0] for first bigram, tuple\n",
    "        print(phrase)\n",
    "    \n",
    "    return ' '.join(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jack', 'be']\n",
      "['jack', 'be', 'quick']\n",
      "['jack', 'be', 'quick', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'jack be quick .'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_gen('jack', u_probs, b_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['over', 'the']\n",
      "['over', 'the', 'candlestick']\n",
      "['over', 'the', 'candlestick', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'over the candlestick .'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_gen('over', u_probs, b_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try NLTK's generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be nimble . . jack jump over the candlestick . over the candlestick .\n",
      "jack be quick . jack be quick . . jack be nimble . the candlestick .\n",
      "be quick . over the candlestick . . the candlestick . . be nimble .\n",
      "jack jump over the candlestick . quick . jack be nimble . jack be\n",
      "quick . jack be quick . . . jack jump over the candlestick .\n",
      "candlestick . over the candlestick . . nimble . jack jump over the\n",
      "candlestick . jack be nimble . jack be nimble . jump over the\n",
      "candlestick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building ngram index...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'be nimble . . jack jump over the candlestick . over the candlestick .\\njack be quick . jack be quick . . jack be nimble . the candlestick .\\nbe quick . over the candlestick . . the candlestick . . be nimble .\\njack jump over the candlestick . quick . jack be nimble . jack be\\nquick . jack be quick . . . jack jump over the candlestick .\\ncandlestick . over the candlestick . . nimble . jack jump over the\\ncandlestick . jack be nimble . jack be nimble . jump over the\\ncandlestick'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltkText = nltk.Text(unigrams)\n",
    "nltkText.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we need a bigger corpus to get more interesting results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building ngram index...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objects , and especially the truth that democratic government has\n",
      "innate capacity to govern its affairs aright through the Province\n",
      "ceded , by any timid forebodings of evil were not to overtake them\n",
      "while I possess the property of the pecuniary estimates for the\n",
      "advancement of civilization . , religion and a reckless disregard of\n",
      "the Argonne , Omaha Beach , Salerno and halfway around the globe , and\n",
      "nothing is more important in the House and the special attention of\n",
      "the Government to interfere with the advice and equipment to free ones\n",
      "; to the public agents intrusted with\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'objects , and especially the truth that democratic government has\\ninnate capacity to govern its affairs aright through the Province\\nceded , by any timid forebodings of evil were not to overtake them\\nwhile I possess the property of the pecuniary estimates for the\\nadvancement of civilization . , religion and a reckless disregard of\\nthe Argonne , Omaha Beach , Salerno and halfway around the globe , and\\nnothing is more important in the House and the special attention of\\nthe Government to interfere with the advice and equipment to free ones\\n; to the public agents intrusted with'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
