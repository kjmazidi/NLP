{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Code accompanies *Natural Language Processing* by KJG Mazidi, all rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Example\n",
    "\n",
    "Using an SMS Spam data set (slightly modified) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). The data set is a collection of 5574 SMS messages that have been labeled as ham or spam. The file is a tab-delimited file with the first column the label and the second the message content. I edited the data set to remove some unwanted columns and add headings. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some necessary packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows and columns: (4837, 2)\n",
      "   spam                                               text\n",
      "0     0  Go until jurong point, crazy.. Available only ...\n",
      "1     0                      Ok lar... Joking wif u oni...\n",
      "2     1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3     0  U dun say so early hor... U c already then say...\n",
      "4     0  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/sms-spam.csv', header=0, usecols=[1,2], encoding='latin-1')\n",
    "print('rows and columns:', df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size:  (3856, 2)\n",
      "test data size:  (981, 2)\n"
     ]
    }
   ],
   "source": [
    "# split df into train and test\n",
    "i = np.random.rand(len(df)) < 0.8\n",
    "train = df[i]\n",
    "test = df[~i]\n",
    "print(\"train data size: \", train.shape)\n",
    "print(\"test data size: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shapes: (3856, 25000) (3856,)\n",
      "test shapes: (981, 25000) (981,)\n",
      "test first five labels: [0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# set up X and Y\n",
    "num_labels = 2\n",
    "vocab_size = 25000\n",
    "batch_size = 100\n",
    "\n",
    "# fit the tokenizer on the training data\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(train.text)\n",
    "\n",
    "x_train = tokenizer.texts_to_matrix(train.text, mode='tfidf')\n",
    "x_test = tokenizer.texts_to_matrix(test.text, mode='tfidf')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train.spam)\n",
    "y_train = encoder.transform(train.spam)\n",
    "y_test = encoder.transform(test.spam)\n",
    "\n",
    "# check shape\n",
    "print(\"train shapes:\", x_train.shape, y_train.shape)\n",
    "print(\"test shapes:\", x_test.shape, y_test.shape)\n",
    "print(\"test first five labels:\", y_test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.5738 - accuracy: 0.8046 - val_loss: 0.4167 - val_accuracy: 0.9145\n",
      "Epoch 2/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.3004 - accuracy: 0.9452 - val_loss: 0.2135 - val_accuracy: 0.9715\n",
      "Epoch 3/30\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.1359 - accuracy: 0.9876 - val_loss: 0.1236 - val_accuracy: 0.9845\n",
      "Epoch 4/30\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0683 - accuracy: 0.9954 - val_loss: 0.0920 - val_accuracy: 0.9870\n",
      "Epoch 5/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0402 - accuracy: 0.9980 - val_loss: 0.0797 - val_accuracy: 0.9870\n",
      "Epoch 6/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9983 - val_loss: 0.0739 - val_accuracy: 0.9870\n",
      "Epoch 7/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0183 - accuracy: 0.9997 - val_loss: 0.0719 - val_accuracy: 0.9870\n",
      "Epoch 8/30\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0136 - accuracy: 0.9997 - val_loss: 0.0715 - val_accuracy: 0.9870\n",
      "Epoch 9/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0105 - accuracy: 0.9997 - val_loss: 0.0708 - val_accuracy: 0.9870\n",
      "Epoch 10/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0084 - accuracy: 0.9997 - val_loss: 0.0724 - val_accuracy: 0.9870\n",
      "Epoch 11/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 0.9997 - val_loss: 0.0722 - val_accuracy: 0.9870\n",
      "Epoch 12/30\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 0.9997 - val_loss: 0.0730 - val_accuracy: 0.9870\n",
      "Epoch 13/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 0.0740 - val_accuracy: 0.9870\n",
      "Epoch 14/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9870\n",
      "Epoch 15/30\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 0.9870\n",
      "Epoch 16/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9870\n",
      "Epoch 17/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9870\n",
      "Epoch 18/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9870\n",
      "Epoch 19/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 0.9870\n",
      "Epoch 20/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9870\n",
      "Epoch 21/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 0.9870\n",
      "Epoch 22/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9870\n",
      "Epoch 23/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9870\n",
      "Epoch 24/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9870\n",
      "Epoch 25/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9870\n",
      "Epoch 26/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9870\n",
      "Epoch 27/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 9.8585e-04 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9870\n",
      "Epoch 28/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 9.1387e-04 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9870\n",
      "Epoch 29/30\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 8.5013e-04 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9870\n",
      "Epoch 30/30\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 7.9371e-04 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9870\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, input_dim=vocab_size, kernel_initializer='normal', activation='relu'))\n",
    "model.add(layers.Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    " \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9857\n",
      "Accuracy:  0.9857288599014282\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('Accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14387717843055725, 0.9857288599014282]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions so we can calculate more metrics\n",
    "pred = model.predict(x_test)\n",
    "pred_labels = [1 if p>0.5 else 0 for p in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5174613e-06],\n",
       "       [9.9997467e-01],\n",
       "       [9.9497914e-01],\n",
       "       [8.6666059e-01],\n",
       "       [1.3214955e-05],\n",
       "       [3.9994189e-10],\n",
       "       [5.6382596e-05],\n",
       "       [5.2508712e-04],\n",
       "       [6.1390595e-13],\n",
       "       [1.6169606e-05]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.9857288481141692\n",
      "precision score:  0.9917355371900827\n",
      "recall score:  0.9022556390977443\n",
      "f1 score:  0.9448818897637795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('accuracy score: ', accuracy_score(y_test, pred_labels))\n",
    "print('precision score: ', precision_score(y_test, pred_labels))\n",
    "print('recall score: ', recall_score(y_test, pred_labels))\n",
    "print('f1 score: ', f1_score(y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was by far the most accurate. Much more work could be done modifying the network topology. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
