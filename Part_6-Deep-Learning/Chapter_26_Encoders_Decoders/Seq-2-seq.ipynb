{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence-to-sequence example\n",
    "\n",
    "This notebook modifies a notebook from Challot's [Keras blog](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html). The code was slightly modified to correct for certain errors that were thrown using a newer version of tensorflow. \n",
    "\n",
    "The data used is from a dataset of English/French pairs of sentences, which you can download here: http://www.manythings.org/anki/\n",
    "\n",
    "The link above has data sets of bilingual sentence pairs for dozens of languages. \n",
    "\n",
    "The approach below separates the encoding from the decoding, in part because training time is quite lengthy. \n",
    "\n",
    "One interesting feature of the approach below is that it generates the text character by character instead of word by word. \n",
    "\n",
    "### Read the data\n",
    "\n",
    "Before getting started, let's look at the data. \n",
    "\n",
    "The code block below reads in the data, which looks like this:\n",
    "\n",
    "```\n",
    "Go.\tVa !\tCC-BY 2.0 (France) Attribution: . . .\n",
    "```\n",
    "The file is tab-delimited. The first item is an English sentence, the second the French translation, and the rest is information we don't care about. \n",
    "\n",
    "For each line in the file, the input text and target text are added to their own lists, while also gathering a set of characters used in the input language and a set of characters in the target language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/fra-eng/fra.txt'\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "\n",
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up some parameters for encoding length based on the input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 71\n",
      "Number of unique output tokens: 93\n",
      "Max sequence length for inputs: 15\n",
      "Max sequence length for outputs: 59\n"
     ]
    }
   ],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the data\n",
    "\n",
    "In order to vectorize the data, an index dictionary is created for the input language, and one for the target language. \n",
    "\n",
    "Then sparse matrices are created for:\n",
    "* decoder input\n",
    "* decoder target\n",
    "* encoder input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "# look at the index dictionaries\n",
    "print(input_token_index['a'])\n",
    "print(target_token_index['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at one of the sparse matrices\n",
    "\n",
    "decoder_input_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some parameters\n",
    "\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code block defines the input layer and the LSTM layer for the encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = layers.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = layers.Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = layers.Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we train the model. This took about 22 minutes on a Mac mini. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 14s 111ms/step - loss: 1.1914 - accuracy: 0.7242 - val_loss: 1.0451 - val_accuracy: 0.7078\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 13s 106ms/step - loss: 0.8613 - accuracy: 0.7684 - val_loss: 0.8535 - val_accuracy: 0.7676\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.6980 - accuracy: 0.8051 - val_loss: 0.7219 - val_accuracy: 0.7902\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 0.6000 - accuracy: 0.8263 - val_loss: 0.6504 - val_accuracy: 0.8076\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 14s 112ms/step - loss: 0.5487 - accuracy: 0.8400 - val_loss: 0.6161 - val_accuracy: 0.8179\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 13s 108ms/step - loss: 0.5097 - accuracy: 0.8503 - val_loss: 0.5975 - val_accuracy: 0.8241\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.4800 - accuracy: 0.8584 - val_loss: 0.5550 - val_accuracy: 0.8361\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.4548 - accuracy: 0.8652 - val_loss: 0.5349 - val_accuracy: 0.8416\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.4334 - accuracy: 0.8709 - val_loss: 0.5202 - val_accuracy: 0.8461\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 0.4144 - accuracy: 0.8761 - val_loss: 0.5097 - val_accuracy: 0.8485\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.3969 - accuracy: 0.8810 - val_loss: 0.4986 - val_accuracy: 0.8511\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.3807 - accuracy: 0.8859 - val_loss: 0.4839 - val_accuracy: 0.8563\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.3662 - accuracy: 0.8900 - val_loss: 0.4716 - val_accuracy: 0.8603\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.3523 - accuracy: 0.8944 - val_loss: 0.4648 - val_accuracy: 0.8621\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.3394 - accuracy: 0.8979 - val_loss: 0.4611 - val_accuracy: 0.8645\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.3273 - accuracy: 0.9016 - val_loss: 0.4574 - val_accuracy: 0.8650\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.3153 - accuracy: 0.9050 - val_loss: 0.4533 - val_accuracy: 0.8672\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.3045 - accuracy: 0.9081 - val_loss: 0.4504 - val_accuracy: 0.8676\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.2940 - accuracy: 0.9110 - val_loss: 0.4488 - val_accuracy: 0.8688\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 0.2838 - accuracy: 0.9140 - val_loss: 0.4431 - val_accuracy: 0.8707\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.2739 - accuracy: 0.9170 - val_loss: 0.4431 - val_accuracy: 0.8706\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.2649 - accuracy: 0.9197 - val_loss: 0.4453 - val_accuracy: 0.8711\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.2564 - accuracy: 0.9222 - val_loss: 0.4429 - val_accuracy: 0.8733\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.2480 - accuracy: 0.9246 - val_loss: 0.4432 - val_accuracy: 0.8725\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.2400 - accuracy: 0.9268 - val_loss: 0.4409 - val_accuracy: 0.8743\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.2319 - accuracy: 0.9291 - val_loss: 0.4486 - val_accuracy: 0.8728\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.2247 - accuracy: 0.9314 - val_loss: 0.4490 - val_accuracy: 0.8745\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.2178 - accuracy: 0.9334 - val_loss: 0.4502 - val_accuracy: 0.8746\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 13s 106ms/step - loss: 0.2111 - accuracy: 0.9356 - val_loss: 0.4523 - val_accuracy: 0.8754\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.2047 - accuracy: 0.9373 - val_loss: 0.4541 - val_accuracy: 0.8761\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1986 - accuracy: 0.9394 - val_loss: 0.4552 - val_accuracy: 0.8768\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1926 - accuracy: 0.9411 - val_loss: 0.4641 - val_accuracy: 0.8756\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1872 - accuracy: 0.9429 - val_loss: 0.4639 - val_accuracy: 0.8756\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1818 - accuracy: 0.9443 - val_loss: 0.4687 - val_accuracy: 0.8764\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1768 - accuracy: 0.9458 - val_loss: 0.4717 - val_accuracy: 0.8749\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1714 - accuracy: 0.9474 - val_loss: 0.4758 - val_accuracy: 0.8753\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1671 - accuracy: 0.9486 - val_loss: 0.4766 - val_accuracy: 0.8758\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1625 - accuracy: 0.9501 - val_loss: 0.4851 - val_accuracy: 0.8739\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 0.1581 - accuracy: 0.9514 - val_loss: 0.4860 - val_accuracy: 0.8758\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1534 - accuracy: 0.9526 - val_loss: 0.4907 - val_accuracy: 0.8757\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1497 - accuracy: 0.9538 - val_loss: 0.4884 - val_accuracy: 0.8769\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1461 - accuracy: 0.9551 - val_loss: 0.4966 - val_accuracy: 0.8756\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.1422 - accuracy: 0.9561 - val_loss: 0.4984 - val_accuracy: 0.8764\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1385 - accuracy: 0.9571 - val_loss: 0.5062 - val_accuracy: 0.8751\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1351 - accuracy: 0.9581 - val_loss: 0.5090 - val_accuracy: 0.8766\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1319 - accuracy: 0.9591 - val_loss: 0.5175 - val_accuracy: 0.8747\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1284 - accuracy: 0.9600 - val_loss: 0.5213 - val_accuracy: 0.8744\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.1254 - accuracy: 0.9608 - val_loss: 0.5235 - val_accuracy: 0.8753\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1224 - accuracy: 0.9621 - val_loss: 0.5306 - val_accuracy: 0.8748\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1194 - accuracy: 0.9627 - val_loss: 0.5310 - val_accuracy: 0.8745\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.1168 - accuracy: 0.9635 - val_loss: 0.5397 - val_accuracy: 0.8754\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1142 - accuracy: 0.9642 - val_loss: 0.5396 - val_accuracy: 0.8746\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1116 - accuracy: 0.9649 - val_loss: 0.5464 - val_accuracy: 0.8733\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1094 - accuracy: 0.9654 - val_loss: 0.5511 - val_accuracy: 0.8747\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.1069 - accuracy: 0.9662 - val_loss: 0.5520 - val_accuracy: 0.8756\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.1046 - accuracy: 0.9670 - val_loss: 0.5529 - val_accuracy: 0.8751\n",
      "Epoch 57/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.1022 - accuracy: 0.9679 - val_loss: 0.5634 - val_accuracy: 0.8747\n",
      "Epoch 58/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0997 - accuracy: 0.9683 - val_loss: 0.5681 - val_accuracy: 0.8749\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0978 - accuracy: 0.9691 - val_loss: 0.5702 - val_accuracy: 0.8746\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0959 - accuracy: 0.9695 - val_loss: 0.5697 - val_accuracy: 0.8749\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0937 - accuracy: 0.9702 - val_loss: 0.5757 - val_accuracy: 0.8746\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0918 - accuracy: 0.9706 - val_loss: 0.5881 - val_accuracy: 0.8737\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0901 - accuracy: 0.9712 - val_loss: 0.5875 - val_accuracy: 0.8739\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0882 - accuracy: 0.9718 - val_loss: 0.5939 - val_accuracy: 0.8737\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.0863 - accuracy: 0.9724 - val_loss: 0.5966 - val_accuracy: 0.8737\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 0.0848 - accuracy: 0.9727 - val_loss: 0.6037 - val_accuracy: 0.8732\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0831 - accuracy: 0.9732 - val_loss: 0.6049 - val_accuracy: 0.8736\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0813 - accuracy: 0.9738 - val_loss: 0.6135 - val_accuracy: 0.8724\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0800 - accuracy: 0.9742 - val_loss: 0.6105 - val_accuracy: 0.8747\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.0785 - accuracy: 0.9745 - val_loss: 0.6141 - val_accuracy: 0.8743\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.0774 - accuracy: 0.9749 - val_loss: 0.6199 - val_accuracy: 0.8736\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.0757 - accuracy: 0.9753 - val_loss: 0.6203 - val_accuracy: 0.8742\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.0742 - accuracy: 0.9760 - val_loss: 0.6237 - val_accuracy: 0.8741\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 13s 107ms/step - loss: 0.0730 - accuracy: 0.9760 - val_loss: 0.6330 - val_accuracy: 0.8733\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.0715 - accuracy: 0.9764 - val_loss: 0.6379 - val_accuracy: 0.8737\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.0701 - accuracy: 0.9771 - val_loss: 0.6364 - val_accuracy: 0.8736\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.0690 - accuracy: 0.9773 - val_loss: 0.6424 - val_accuracy: 0.8724\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.0678 - accuracy: 0.9776 - val_loss: 0.6407 - val_accuracy: 0.8744\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0662 - accuracy: 0.9780 - val_loss: 0.6462 - val_accuracy: 0.8735\n",
      "Epoch 80/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0653 - accuracy: 0.9783 - val_loss: 0.6599 - val_accuracy: 0.8732\n",
      "Epoch 81/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.0642 - accuracy: 0.9785 - val_loss: 0.6587 - val_accuracy: 0.8738\n",
      "Epoch 82/100\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 0.0632 - accuracy: 0.9788 - val_loss: 0.6637 - val_accuracy: 0.8732\n",
      "Epoch 83/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0625 - accuracy: 0.9792 - val_loss: 0.6688 - val_accuracy: 0.8734\n",
      "Epoch 84/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.0614 - accuracy: 0.9793 - val_loss: 0.6674 - val_accuracy: 0.8733\n",
      "Epoch 85/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.0602 - accuracy: 0.9800 - val_loss: 0.6794 - val_accuracy: 0.8726\n",
      "Epoch 86/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0593 - accuracy: 0.9799 - val_loss: 0.6710 - val_accuracy: 0.8734\n",
      "Epoch 87/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.0584 - accuracy: 0.9803 - val_loss: 0.6846 - val_accuracy: 0.8725\n",
      "Epoch 88/100\n",
      "125/125 [==============================] - 13s 108ms/step - loss: 0.0573 - accuracy: 0.9805 - val_loss: 0.6855 - val_accuracy: 0.8722\n",
      "Epoch 89/100\n",
      "125/125 [==============================] - 14s 110ms/step - loss: 0.0569 - accuracy: 0.9807 - val_loss: 0.6913 - val_accuracy: 0.8721\n",
      "Epoch 90/100\n",
      "125/125 [==============================] - 13s 108ms/step - loss: 0.0555 - accuracy: 0.9813 - val_loss: 0.6897 - val_accuracy: 0.8722\n",
      "Epoch 91/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0548 - accuracy: 0.9814 - val_loss: 0.6910 - val_accuracy: 0.8729\n",
      "Epoch 92/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0539 - accuracy: 0.9816 - val_loss: 0.6923 - val_accuracy: 0.8726\n",
      "Epoch 93/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.0534 - accuracy: 0.9817 - val_loss: 0.6991 - val_accuracy: 0.8731\n",
      "Epoch 94/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.0526 - accuracy: 0.9821 - val_loss: 0.7055 - val_accuracy: 0.8735\n",
      "Epoch 95/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0514 - accuracy: 0.9823 - val_loss: 0.6982 - val_accuracy: 0.8729\n",
      "Epoch 96/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0512 - accuracy: 0.9822 - val_loss: 0.7102 - val_accuracy: 0.8720\n",
      "Epoch 97/100\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.0504 - accuracy: 0.9823 - val_loss: 0.7112 - val_accuracy: 0.8728\n",
      "Epoch 98/100\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.0498 - accuracy: 0.9827 - val_loss: 0.7134 - val_accuracy: 0.8724\n",
      "Epoch 99/100\n",
      "125/125 [==============================] - 14s 109ms/step - loss: 0.0489 - accuracy: 0.9830 - val_loss: 0.7247 - val_accuracy: 0.8723\n",
      "Epoch 100/100\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 0.0484 - accuracy: 0.9830 - val_loss: 0.7161 - val_accuracy: 0.8723\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "# Save model\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference mode\n",
    "\n",
    "Now that the model is trained, here are the next steps:\n",
    "\n",
    "* encode the input and retrieve initial decoder state\n",
    "* run one step of decoder with this initial state and a 'start' token as target; the output will be the next token\n",
    "* repeate with current target and current states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling models\n",
    "encoder_model = models.Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = layers.Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = layers.Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = models.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a function to encode the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the code in the notebook takes in the encoder input sequence from the training data, and decoding it to get an output sentence. This is simply illustrating what the model learned, not evaluating how well it could perform on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "for seq_index in range(10):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    \n",
    "    inputs.append(input_texts[seq_index])\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    outputs.append(decode_sequence(input_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Va !\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Salut !\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Salut !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Cours !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Cours !\n",
      "\n",
      "-\n",
      "Input sentence: Who?\n",
      "Decoded sentence: Qui ?\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Ça alors !\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Au feu !\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: À l'aide !\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Saute.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output a few\n",
    "\n",
    "for i in range(10):\n",
    "    print('-')\n",
    "    print('Input sentence:', inputs[i])\n",
    "    print('Decoded sentence:', outputs[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
